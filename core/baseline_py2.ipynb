{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T06:15:55.896189Z",
     "start_time": "2018-10-24T06:15:55.879165Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import gensim\n",
    "import keras\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, LSTM, GRU, Embedding, Flatten, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载词嵌入矩阵、数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T06:14:30.714980Z",
     "start_time": "2018-10-24T06:14:30.320443Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_model = gensim.models.KeyedVectors.load_word2vec_format('../models/word2vec.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T06:14:40.141518Z",
     "start_time": "2018-10-24T06:14:36.529064Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../datasets/train_processed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成embedding字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T06:14:58.752995Z",
     "start_time": "2018-10-24T06:14:58.735177Z"
    }
   },
   "outputs": [],
   "source": [
    "word2index = dict(zip(embedding_model.index2word, range(1, len(embedding_model.index2word) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T06:15:04.625522Z",
     "start_time": "2018-10-24T06:15:04.619764Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate_word_to_index(sequence):\n",
    "    return [word2index[w] if w in word2index else 0 for w in sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T06:15:10.619631Z",
     "start_time": "2018-10-24T06:15:10.376614Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_metric = np.array([embedding_model[word] for word, _ in word2index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T06:15:49.374200Z",
     "start_time": "2018-10-24T06:15:15.551031Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heyao/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py:2: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X1 = pad_sequences([translate_word_to_index(s) for s in data.question1_words.values], 50)\n",
    "X2 = pad_sequences([translate_word_to_index(s) for s in data.question2_words.values], 50)\n",
    "y = data.is_duplicate.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T06:15:58.150262Z",
     "start_time": "2018-10-24T06:15:57.938510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:\n",
      " X1 train: (323429, 50) X1 val: (80858, 50) X2 train: (323429, 50) X2 val: (80858, 50)\n",
      "y shape:\n",
      " y train: (323429,) y val: (80858,)\n"
     ]
    }
   ],
   "source": [
    "X1_train, X1_val, X2_train, X2_val, y_train, y_val = train_test_split(X1, X2, y, test_size=0.2, random_state=42)\n",
    "print(\"X shape:\\n\", \"X1 train:\", X1_train.shape, \"X1 val:\", X1_val.shape, \"X2 train:\", X2_train.shape, \"X2 val:\", X2_val.shape)\n",
    "print(\"y shape:\\n\", \"y train:\", y_train.shape, \"y val:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T06:16:10.749914Z",
     "start_time": "2018-10-24T06:16:10.743977Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LEN = 50\n",
    "WORD_DIM = 128\n",
    "num_words = len(embedding_metric) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T06:28:19.781294Z",
     "start_time": "2018-10-24T06:28:18.785162Z"
    }
   },
   "outputs": [],
   "source": [
    "# cnn\n",
    "q_a = Input(shape=(MAX_SEQUENCE_LEN,))\n",
    "q_b = Input(shape=(MAX_SEQUENCE_LEN,))\n",
    "shared_embedding = Embedding(input_dim=num_words, output_dim=WORD_DIM, \n",
    "                             embeddings_initializer=keras.initializers.Constant(embedding_metric), \n",
    "                             input_length=MAX_SEQUENCE_LEN, trainable=False)\n",
    "# shared_lstm = LSTM(32, activation='relu')\n",
    "embed_a = shared_embedding(q_a)\n",
    "embed_b = shared_embedding(q_b)\n",
    "# encoded_a = shared_lstm(embed_a)\n",
    "# encoded_b = shared_lstm(embed_b)\n",
    "shared_cnn1 = Conv1D(16, 2, padding='same', activation='relu')\n",
    "shared_cnn2 = Conv1D(32, 2, padding='same', activation='relu')\n",
    "shared_cnn3 = Conv1D(64, 2, padding='same', activation='relu')\n",
    "# shared_cnn4 = Conv1D(128, 2, padding='same', activation='relu')\n",
    "shared_pool1 = MaxPooling1D(2, strides=1)\n",
    "shared_pool2 = MaxPooling1D(2, strides=1)\n",
    "shared_pool3 = MaxPooling1D(2, strides=1)\n",
    "# shared_pool4 = MaxPooling1D(2, strides=1)\n",
    "cnn_a1 = shared_pool1(shared_cnn1(embed_a))\n",
    "cnn_b1 = shared_pool1(shared_cnn1(embed_b))\n",
    "cnn_a2 = shared_pool2(shared_cnn2(cnn_a1))\n",
    "cnn_b2 = shared_pool2(shared_cnn2(cnn_b1))\n",
    "# cnn_a3 = shared_pool3(shared_cnn3(cnn_a2))\n",
    "# cnn_b3 = shared_pool3(shared_cnn3(cnn_b2))\n",
    "encoded_a = Flatten()(shared_pool3(shared_cnn3(cnn_a2)))\n",
    "encoded_b = Flatten()(shared_pool3(shared_cnn3(cnn_b2)))\n",
    "\n",
    "merged_vec = keras.layers.concatenate([encoded_a, encoded_b])\n",
    "hidden1 = Dense(64, activation='relu')(merged_vec)\n",
    "hidden1_drop = Dropout(0.5)(hidden1)\n",
    "output = Dense(1, activation='sigmoid')(hidden1_drop)\n",
    "model = Model(inputs=[q_a, q_b], outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fully-connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T06:16:49.493848Z",
     "start_time": "2018-10-24T06:16:48.496839Z"
    }
   },
   "outputs": [],
   "source": [
    "q_a = Input(shape=(MAX_SEQUENCE_LEN,))\n",
    "q_b = Input(shape=(MAX_SEQUENCE_LEN,))\n",
    "shared_embedding = Embedding(input_dim=num_words, output_dim=WORD_DIM, \n",
    "                             embeddings_initializer=keras.initializers.Constant(embedding_metric), \n",
    "                             input_length=MAX_SEQUENCE_LEN, trainable=False)\n",
    "\n",
    "embed_a = shared_embedding(q_a)\n",
    "embed_b = shared_embedding(q_b)\n",
    "shared_fc1 = Dense(64, activation='relu')\n",
    "shared_fc2 = Dense(32, activation='relu')\n",
    "shared_fc3 = Dense(8, activation='relu')\n",
    "fc_a1 = shared_fc1(embed_a)\n",
    "fc_b1 = shared_fc1(embed_b)\n",
    "fc_a2 = shared_fc2(fc_a1)\n",
    "fc_b2 = shared_fc2(fc_a1)\n",
    "fc_a3 = shared_fc3(fc_a2)\n",
    "fc_b3 = shared_fc3(fc_a2)\n",
    "merged_vec = Flatten()(keras.layers.concatenate([fc_a3, fc_b3]))\n",
    "hidden1 = Dense(8, activation='relu')(merged_vec)\n",
    "output = Dense(1, activation='sigmoid')(hidden1)\n",
    "model = Model(inputs=[q_a, q_b], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T06:28:24.964952Z",
     "start_time": "2018-10-24T06:28:24.889096Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile('adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T08:42:48.348766Z",
     "start_time": "2018-10-24T06:28:25.457290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 323429 samples, validate on 80858 samples\n",
      "Epoch 1/50\n",
      "323429/323429 [==============================] - 149s 461us/step - loss: 0.6336 - acc: 0.6513 - val_loss: 0.6030 - val_acc: 0.6814\n",
      "Epoch 2/50\n",
      "323429/323429 [==============================] - 188s 581us/step - loss: 0.5972 - acc: 0.6877 - val_loss: 0.5767 - val_acc: 0.7012\n",
      "Epoch 3/50\n",
      "323429/323429 [==============================] - 162s 501us/step - loss: 0.5731 - acc: 0.7066 - val_loss: 0.5551 - val_acc: 0.7138\n",
      "Epoch 4/50\n",
      "323429/323429 [==============================] - 163s 504us/step - loss: 0.5561 - acc: 0.7181 - val_loss: 0.5495 - val_acc: 0.7193\n",
      "Epoch 5/50\n",
      "323429/323429 [==============================] - 164s 508us/step - loss: 0.5433 - acc: 0.7268 - val_loss: 0.5385 - val_acc: 0.7244\n",
      "Epoch 6/50\n",
      "323429/323429 [==============================] - 160s 495us/step - loss: 0.5323 - acc: 0.7336 - val_loss: 0.5254 - val_acc: 0.7401\n",
      "Epoch 7/50\n",
      "323429/323429 [==============================] - 169s 524us/step - loss: 0.5226 - acc: 0.7395 - val_loss: 0.5211 - val_acc: 0.7427\n",
      "Epoch 8/50\n",
      "323429/323429 [==============================] - 156s 483us/step - loss: 0.5141 - acc: 0.7444 - val_loss: 0.5164 - val_acc: 0.7473\n",
      "Epoch 9/50\n",
      "323429/323429 [==============================] - 168s 520us/step - loss: 0.5057 - acc: 0.7484 - val_loss: 0.5117 - val_acc: 0.7501\n",
      "Epoch 10/50\n",
      "323429/323429 [==============================] - 161s 499us/step - loss: 0.4981 - acc: 0.7525 - val_loss: 0.5110 - val_acc: 0.7503\n",
      "Epoch 11/50\n",
      "323429/323429 [==============================] - 160s 493us/step - loss: 0.4911 - acc: 0.7557 - val_loss: 0.5057 - val_acc: 0.7544\n",
      "Epoch 12/50\n",
      "323429/323429 [==============================] - 153s 472us/step - loss: 0.4846 - acc: 0.7595 - val_loss: 0.5056 - val_acc: 0.7551\n",
      "Epoch 13/50\n",
      "323429/323429 [==============================] - 155s 480us/step - loss: 0.4775 - acc: 0.7635 - val_loss: 0.5052 - val_acc: 0.7560\n",
      "Epoch 14/50\n",
      "323429/323429 [==============================] - 164s 506us/step - loss: 0.4709 - acc: 0.7657 - val_loss: 0.5048 - val_acc: 0.7577\n",
      "Epoch 15/50\n",
      "323429/323429 [==============================] - 154s 475us/step - loss: 0.4656 - acc: 0.7680 - val_loss: 0.5024 - val_acc: 0.7569\n",
      "Epoch 16/50\n",
      "323429/323429 [==============================] - 165s 511us/step - loss: 0.4594 - acc: 0.7718 - val_loss: 0.5032 - val_acc: 0.7571\n",
      "Epoch 17/50\n",
      "323429/323429 [==============================] - 165s 509us/step - loss: 0.4547 - acc: 0.7725 - val_loss: 0.5055 - val_acc: 0.7571\n",
      "Epoch 18/50\n",
      "323429/323429 [==============================] - 169s 524us/step - loss: 0.4491 - acc: 0.7761 - val_loss: 0.5039 - val_acc: 0.7600\n",
      "Epoch 19/50\n",
      "323429/323429 [==============================] - 170s 526us/step - loss: 0.4456 - acc: 0.7769 - val_loss: 0.5040 - val_acc: 0.7597\n",
      "Epoch 20/50\n",
      "323429/323429 [==============================] - 176s 545us/step - loss: 0.4403 - acc: 0.7785 - val_loss: 0.5012 - val_acc: 0.7591\n",
      "Epoch 21/50\n",
      "323429/323429 [==============================] - 164s 506us/step - loss: 0.4367 - acc: 0.7793 - val_loss: 0.5056 - val_acc: 0.7585\n",
      "Epoch 22/50\n",
      "323429/323429 [==============================] - 158s 488us/step - loss: 0.4338 - acc: 0.7806 - val_loss: 0.5045 - val_acc: 0.7596\n",
      "Epoch 23/50\n",
      "323429/323429 [==============================] - 160s 496us/step - loss: 0.4288 - acc: 0.7821 - val_loss: 0.5090 - val_acc: 0.7608\n",
      "Epoch 24/50\n",
      "323429/323429 [==============================] - 160s 495us/step - loss: 0.4266 - acc: 0.7833 - val_loss: 0.5070 - val_acc: 0.7606\n",
      "Epoch 25/50\n",
      "323429/323429 [==============================] - 159s 491us/step - loss: 0.4234 - acc: 0.7851 - val_loss: 0.5088 - val_acc: 0.7598\n",
      "Epoch 26/50\n",
      "323429/323429 [==============================] - 164s 506us/step - loss: 0.4204 - acc: 0.7852 - val_loss: 0.5115 - val_acc: 0.7598\n",
      "Epoch 27/50\n",
      "323429/323429 [==============================] - 170s 526us/step - loss: 0.4175 - acc: 0.7868 - val_loss: 0.5078 - val_acc: 0.7616\n",
      "Epoch 28/50\n",
      "323429/323429 [==============================] - 166s 514us/step - loss: 0.4133 - acc: 0.7889 - val_loss: 0.5121 - val_acc: 0.7608\n",
      "Epoch 29/50\n",
      "323429/323429 [==============================] - 169s 522us/step - loss: 0.4102 - acc: 0.7897 - val_loss: 0.5113 - val_acc: 0.7603\n",
      "Epoch 30/50\n",
      "323429/323429 [==============================] - 170s 525us/step - loss: 0.4088 - acc: 0.7896 - val_loss: 0.5126 - val_acc: 0.7616\n",
      "Epoch 31/50\n",
      "323429/323429 [==============================] - 181s 558us/step - loss: 0.4063 - acc: 0.7907 - val_loss: 0.5167 - val_acc: 0.7596\n",
      "Epoch 32/50\n",
      "323429/323429 [==============================] - 186s 575us/step - loss: 0.4019 - acc: 0.7929 - val_loss: 0.5195 - val_acc: 0.7600\n",
      "Epoch 33/50\n",
      "323429/323429 [==============================] - 170s 526us/step - loss: 0.4013 - acc: 0.7923 - val_loss: 0.5157 - val_acc: 0.7617\n",
      "Epoch 34/50\n",
      "323429/323429 [==============================] - 156s 483us/step - loss: 0.3972 - acc: 0.7964 - val_loss: 0.5206 - val_acc: 0.7605oss: 0.3972 - acc: 0.796\n",
      "Epoch 35/50\n",
      "323429/323429 [==============================] - 163s 505us/step - loss: 0.3958 - acc: 0.7944 - val_loss: 0.5169 - val_acc: 0.7594\n",
      "Epoch 36/50\n",
      "323429/323429 [==============================] - 152s 469us/step - loss: 0.3918 - acc: 0.7991 - val_loss: 0.5238 - val_acc: 0.7596\n",
      "Epoch 37/50\n",
      "323429/323429 [==============================] - 148s 458us/step - loss: 0.3909 - acc: 0.7970 - val_loss: 0.5275 - val_acc: 0.7601\n",
      "Epoch 38/50\n",
      "323429/323429 [==============================] - 165s 511us/step - loss: 0.3879 - acc: 0.7988 - val_loss: 0.5354 - val_acc: 0.7626\n",
      "Epoch 39/50\n",
      "323429/323429 [==============================] - 167s 516us/step - loss: 0.3871 - acc: 0.8009 - val_loss: 0.5329 - val_acc: 0.7622\n",
      "Epoch 40/50\n",
      "323429/323429 [==============================] - 162s 500us/step - loss: 0.3840 - acc: 0.8019 - val_loss: 0.5403 - val_acc: 0.7611\n",
      "Epoch 41/50\n",
      "323429/323429 [==============================] - 159s 491us/step - loss: 0.3821 - acc: 0.8027 - val_loss: 0.5398 - val_acc: 0.7637\n",
      "Epoch 42/50\n",
      "323429/323429 [==============================] - 157s 484us/step - loss: 0.3794 - acc: 0.8031 - val_loss: 0.5353 - val_acc: 0.7632\n",
      "Epoch 43/50\n",
      "323429/323429 [==============================] - 158s 489us/step - loss: 0.3776 - acc: 0.8042 - val_loss: 0.5348 - val_acc: 0.7617\n",
      "Epoch 44/50\n",
      "323429/323429 [==============================] - 171s 529us/step - loss: 0.3783 - acc: 0.8025 - val_loss: 0.5376 - val_acc: 0.7614\n",
      "Epoch 45/50\n",
      "323429/323429 [==============================] - 165s 511us/step - loss: 0.3748 - acc: 0.8058 - val_loss: 0.5487 - val_acc: 0.7635\n",
      "Epoch 46/50\n",
      "323429/323429 [==============================] - 156s 482us/step - loss: 0.3717 - acc: 0.8070 - val_loss: 0.5390 - val_acc: 0.7622\n",
      "Epoch 47/50\n",
      "323429/323429 [==============================] - 147s 453us/step - loss: 0.3709 - acc: 0.8068 - val_loss: 0.5431 - val_acc: 0.7603\n",
      "Epoch 48/50\n",
      "323429/323429 [==============================] - 138s 427us/step - loss: 0.3689 - acc: 0.8068 - val_loss: 0.5422 - val_acc: 0.7612\n",
      "Epoch 49/50\n",
      "323429/323429 [==============================] - 125s 387us/step - loss: 0.3678 - acc: 0.8081 - val_loss: 0.5425 - val_acc: 0.7599\n",
      "Epoch 50/50\n",
      "323429/323429 [==============================] - 125s 387us/step - loss: 0.3648 - acc: 0.8084 - val_loss: 0.5575 - val_acc: 0.7628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x130ae9450>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X1_train, X2_train], y_train, batch_size=256, epochs=50, \n",
    "          validation_data=([X1_val, X2_val], y_val))  # , callbacks=[TensorBoard('../logs')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-24T08:54:18.199886Z",
     "start_time": "2018-10-24T08:54:12.809323Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('../models/baseline_cnn3_fc64_drop.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
